{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwritten_Digits_Recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNlWtv0xEJ3kww4jyoQ4c6Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shashank123-hub/HDR-app/blob/master/Handwritten_Digits_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtXEkqL68lJW",
        "colab_type": "text"
      },
      "source": [
        "#**Project topic : Handwritten Digit Recognition**\n",
        "\n",
        "> The goal of this topic is to recognize handwritten digits by the user using the Convolution Neural Networks(CNNs).  \n",
        "We'll also build a GUI in which we can draw as well as recognize the digit right away.\n",
        "\n",
        "\n",
        "> Modules used in this projects are the **Keras library** for deep learning and the **Tkinter library** for building the GUI.\n",
        "\n",
        "> Also, the dataset used here is the **MNIST dataset**. It contains 60,000 images of handwritten digits from zero to nine and 10,000 images for testing. It has 10 different classes and the images are represented as 28*28 matrix with each cell contains with grayscale pixel value.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-R7aGJYPq8F",
        "colab_type": "text"
      },
      "source": [
        "#**Step 1 : Installing the dependancies and load the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fNggriP8mZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "outputId": "81664229-96d3-4d8b-f29c-5c50830e97bc"
      },
      "source": [
        "!pip install numpy\n",
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install pillow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.30.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (47.3.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.1.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Ffd0rORsmw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "b79580c7-d671-4820-c4fa-7df17bbb8186"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "#Splitting the data between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 5s 0us/step\n",
            "(60000, 28, 28) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhGqRMJY8ml7",
        "colab_type": "text"
      },
      "source": [
        "#**Step 2 : Preprocess the data**\n",
        "\n",
        "> This step primarily involves making our data ready for the neural network to be trained. The dimension of the training data is (60000,28,28) and the CNN model will require one more dimension to the shape (60000,28,28,1).    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0aCwyfu8cVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "c5c5e92e-ec96-420c-c297-e1dfc0523de2"
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=None)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=None)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "\n",
        "print('x_train shape/Input dataset shape:', x_train.shape)\n",
        "print('Train samples :',x_train.shape[0])\n",
        "print('Test samples :',x_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape/Input dataset shape: (60000, 28, 28, 1)\n",
            "Train samples : 60000\n",
            "Test samples : 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXab5EOX8tSW",
        "colab_type": "text"
      },
      "source": [
        "#**Step 3 : Creating the model**\n",
        "\n",
        "> Our model simply consist of convolutional and pooling layer with dropouts for each layer.\n",
        "\n",
        "\n",
        "\n",
        "> The optimizer used here is the **Adadelta optimizer**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht6cdN888tz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape = input_shape)) #a convolutional neural layer\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))  #another CNN layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))  #pooling layer downsampling the images     \n",
        "model.add(Dropout(0.25))  #dropout for the above layer\n",
        "model.add(Flatten())  #flatten layer to convert data into 1-D/flattening the data\n",
        "model.add(Dense(256, activation='relu'))  #third dense layer\n",
        "model.add(Dropout(0.5))  #dropout for the above layer\n",
        "model.add(Dense(num_classes, activation='softmax'))  #final dense layer  \n",
        "\n",
        "model.compile(loss = keras.losses.categorical_crossentropy, \n",
        "optimizer = keras.optimizers.Adadelta() ,metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BYzOGIv8uPT",
        "colab_type": "text"
      },
      "source": [
        "#**Step 4 : Training the compiled model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q2se5m48udg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "7c080ec8-4d8e-409b-b3ce-0ca4979ebfeb"
      },
      "source": [
        "hist = model.fit(x_train, y_train, batch_size=batch_size,\n",
        "epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "print(\"The model has been successfully trained\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 0.2258 - accuracy: 0.9305 - val_loss: 0.0486 - val_accuracy: 0.9837\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 9s 158us/step - loss: 0.0696 - accuracy: 0.9783 - val_loss: 0.0359 - val_accuracy: 0.9874\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0505 - accuracy: 0.9843 - val_loss: 0.0322 - val_accuracy: 0.9879\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0410 - accuracy: 0.9875 - val_loss: 0.0264 - val_accuracy: 0.9909\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0349 - accuracy: 0.9898 - val_loss: 0.0258 - val_accuracy: 0.9902\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.0247 - val_accuracy: 0.9921\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.0233 - val_accuracy: 0.9926\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.0232 - val_accuracy: 0.9919\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0241 - val_accuracy: 0.9928\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 0.0239 - val_accuracy: 0.9921\n",
            "The model has been successfully trained\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1pBF7twpUjK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "51229d96-8443-4a8d-8251-5ec6340591f7"
      },
      "source": [
        "model.save('HDRmodel.h5')\n",
        "print('Saving the model as HDRmodel.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving the model as HDRmodel.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApCIqUd88uqZ",
        "colab_type": "text"
      },
      "source": [
        "#**Step 5 : Evaluating the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9yrCeF78u-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ac49e9cf-bcde-4d3e-895f-6819659fc0ec"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose =0)\n",
        "print('Loss percentage = ', score[0]*100)\n",
        "print('Accuracy percentage = ', score[1]*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss percentage =  2.3866059646923894\n",
            "Accuracy percentage =  99.21000003814697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PPYBz0irqFE",
        "colab_type": "text"
      },
      "source": [
        "#**Step 6 : Creating GUI for prediction**\n",
        "\n",
        "\n",
        "\n",
        "> This step has been done seperately since Colab does not support Tkinter library for GUI implementation the respective file has been saved as \"project.py\"\n",
        "\n"
      ]
    }
  ]
}